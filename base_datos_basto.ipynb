{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic,great_circle\n",
    "from geopy import Point\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import math\n",
    "import random\n",
    "import datetime\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mongo = pymongo.MongoClient('localhost:27017')#'mongodb+srv://brandon:brandon1@cluster0.tfvievv.mongodb.net/?retryWrites=true&w=majority')\n",
    "\n",
    "# Seleccionar una base de datos existente o crear una nueva llamada 'test'.\n",
    "db = data_mongo['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mongo_data(collection):\n",
    "    mongoColle= db[collection]\n",
    "    data= list(mongoColle.find())\n",
    "    df= pd.json_normalize(data,sep='_')\n",
    "    df._id=df._id.astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices= mongo_data('devices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_devices(data,uuid):\n",
    "    data=data[data.UUID==uuid]\n",
    "    data=data.drop(data[data.dataRowData_lat.isna()].index)\n",
    "    data.reset_index()\n",
    "    return data\n",
    "\n",
    "def gps_data(data):\n",
    "    gps= data[['dataRowData_lat','dataRowData_lng']]\n",
    "    gps = gps.dropna()\n",
    "    return gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancia_recorrida(data):\n",
    "    cordena1=tuple(data.iloc[0][['dataRowData_lat','dataRowData_lng']].values)\n",
    "    cordena2= tuple(data.iloc[-1][['dataRowData_lat','dataRowData_lng']].values)\n",
    "    dista_km= great_circle(cordena1,cordena2).kilometers\n",
    "    return dista_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interview_vaca(data): # tratar de filtrar por perimetro porque si hay valores (que los hay)fuera de rango de los -90 90 da error\n",
    "    data_dis=[]\n",
    "    data_vel=[]\n",
    "    data_time=[]\n",
    "    for i in range(0,data.shape[0]+1):\n",
    "        try:\n",
    "            dista_km= great_circle(tuple(data.iloc[i][['dataRowData_lat','dataRowData_lng']].values),tuple(data.iloc[i+1][['dataRowData_lat','dataRowData_lng']].values)).kilometers\n",
    "            if dista_km <= 8.:\n",
    "                data_dis.append(dista_km)\n",
    "            if data.iloc[i].dataRowData_gpsVel:\n",
    "                data_vel.append(data.iloc[i].dataRowData_gpsVel)\n",
    "                data_time.append(dista_km/data.iloc[i].dataRowData_gpsVel)\n",
    "            else:\n",
    "                data_time.append(dista_km/pd.Series(data_vel).mean())# les puede dar error si el array de velocidad esta vacio... toma el valor promedio de las velocidades que hay hasta el momento\n",
    "        except IndexError:\n",
    "            pass\n",
    "    return data_dis,data_vel,data_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perimetro_aprox(hectarea):\n",
    "    hect=hectarea\n",
    "    lado = math.sqrt(hect)*10\n",
    "    perim = lado*4\n",
    "    return perim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setle_clean(select):\n",
    "        de= db['settlements']\n",
    "        obj= de.find_one({'name':select})\n",
    "        df_setle= pd.json_normalize(obj,sep='')\n",
    "        df_setle['latitud_c']=df_setle.centralPoint.apply(lambda x: x[0]['lat'] if 'lat' in x[0] else None)\n",
    "        df_setle['longitud_c']=df_setle.centralPoint.apply(lambda x: x[0]['lng'] if 'lng' in x[0] else None)\n",
    "        setle_n = df_setle[['_id','hectares','registerNumber','headsCount','name','latitud_c','longitud_c']]\n",
    "        return setle_n\n",
    "\n",
    "def conect_animal():\n",
    "        df_animal=mongo_data('animals')\n",
    "        df_animal['animalSettlement']=df_animal['animalSettlement'].apply(lambda x:x[0])\n",
    "        df_animal.animalSettlement=df_animal.animalSettlement.astype(str)\n",
    "        result= df_animal[(df_animal.caravanaNumber.str.contains('AGUADA'))|(df_animal.caravanaNumber.str.contains('PUNTO_FIJO'))]#lo use para extraer un csv con aguadas y puntos fijos\n",
    "        return result\n",
    "\n",
    "def update_aguada(setle):\n",
    "        df_devis= mongo_data('devices')\n",
    "        df_devis.deviceAnimalID=df_devis.deviceAnimalID.astype(str)\n",
    "        data_devise = df_devis[df_devis.deviceType=='PUNTO FIJO'] \n",
    "        aguadas= conect_animal()\n",
    "        x= aguadas[aguadas['animalSettlement']==setle]\n",
    "        agua =data_devise[data_devise.deviceAnimalID.isin(x._id)]\n",
    "        return agua\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_area_perimetro(data:pd.DataFrame,setle:str):\n",
    "    setle= setle_clean(setle)\n",
    "    gdf= gpd.GeoDataFrame(data,crs='EPSG:4326',geometry=gpd.points_from_xy(data.dataRowData_lng,data.dataRowData_lat))\n",
    "    setle_lat=setle['latitud_c'].values[0]\n",
    "    setle_lng=setle['longitud_c'].values[0]\n",
    "    hectareas=setle['hectares'].values[0]\n",
    "    punto_referencia= Point(setle_lng,setle_lat)\t\n",
    "    per_kilo= perimetro_aprox(hectareas)\n",
    "    circulo= punto_referencia.buffer(per_kilo/111.32) # valor 1 grado aprox en kilometro en el ecuador \n",
    "    on_perimetro= gdf[gdf.geometry.within(circulo)]\n",
    "    agua = update_aguada(setle._id.values[0])\n",
    "    on_perimetro = on_perimetro.drop(on_perimetro[on_perimetro['UUID'].isin(agua.deviceMACAddress.unique())].index)\n",
    "    return on_perimetro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colores y Graficas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_color():\n",
    "    \"\"\"Genera un color cálido aleatorio en formato hexadecimal.\"\"\"\n",
    "    # n = random.randint(2,100)\n",
    "    # paleta= sns.color_palette(\"deep\",n_colors=n)\n",
    "    # colores_hex = [mcolors.rgb2hex(color) for color in paleta]\n",
    "    # return colores_hex[random.randint(1,n-1)]\n",
    "    while True:\n",
    "        color ='#' + ''.join(random.choices(string.hexdigits[:-6], k=6))\n",
    "        # Comprueba si el color es cálido\n",
    "        r, g, b = int(color[1:3], 16), int(color[3:5], 16), int(color[5:7], 16)\n",
    "        if r > g and r > b and abs(r-g) < 60:\n",
    "            return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafica_gps(datos_gps,graf,color):\n",
    "    for i , d in datos_gps.iterrows():\n",
    "        folium.Marker(location=[d['dataRowData_lat'],d['dataRowData_lng']]).add_to(graf)\n",
    "    folium.PolyLine(locations=datos_gps,color=color).add_to(graf) #necesitya una funcion que me genere colores aleatorio para identificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graf_muuu(list_vacas,posicion_initial,data):# graficas con folium\n",
    "    colores=[]\n",
    "    aux=0\n",
    "    mp=folium.Map()\n",
    "    for i in list_vacas:\n",
    "        color = random_color()\n",
    "        colores.append(color)\n",
    "        while color in colores:\n",
    "            color =random_color()\n",
    "        if aux == 0:\n",
    "            dta=data_devices(data, i )\n",
    "            dta_gps= gps_data(dta)\n",
    "            mp=folium.Map(location=posicion_initial,zoom_start=15)\n",
    "            grafica_gps(dta_gps,mp,color)\n",
    "            aux = 1\n",
    "        else:\n",
    "            dta=data_devices(data, i )\n",
    "            dta_gps= gps_data(dta)\n",
    "            grafica_gps(dta_gps,mp,color)\n",
    "            aux = 1\n",
    "    return mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapbox_access_token = 'pk.eyJ1IjoibmVzdG9yMTYwOCIsImEiOiJjbGc5b2J2d3gwOHgwM2xwamd3cGE4cmExIn0.bPWyeRa73WyNqm1nBNJOvQ' \n",
    "\n",
    "def uni_graf(data,color,fig):\n",
    "\n",
    "    fig.add_trace(go.Scattermapbox(\n",
    "        lat=data.dataRowData_lat.values,\n",
    "        lon=data.dataRowData_lng.values,\n",
    "        mode='lines+markers',\n",
    "        line=dict(\n",
    "            width=2,\n",
    "            color=color,\n",
    "        ),\n",
    "        marker=go.scattermapbox.Marker(\n",
    "            size=8,\n",
    "            color=color,\n",
    "            symbol='circle'\n",
    "        ),\n",
    "    ))\n",
    "    return fig\n",
    "\n",
    "def grafic_map(data,list_vacas,lat_orig,lng_orig,fig):\n",
    "    colores=[]\n",
    "    for i in list_vacas:\n",
    "        color = random_color()\n",
    "        colores.append(color)\n",
    "        while color in colores:\n",
    "            color =random_color()\n",
    "        dta=data_devices(data, i )\n",
    "        dta_gps= gps_data(dta)\n",
    "        uni_graf(dta_gps,color,fig)\n",
    "        \n",
    "    fig.update_layout(\n",
    "        mapbox=dict(\n",
    "            style='satellite', \n",
    "            accesstoken=mapbox_access_token,\n",
    "            zoom=14, \n",
    "            center=dict(lat=lat_orig,lon=lng_orig),\n",
    "        ),\n",
    "        showlegend=False\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graf_aguada(data,fig):\n",
    "\n",
    "    fig.add_trace(go.Scattermapbox(\n",
    "    lat=data.dataRowData_lat.values,\n",
    "    lon=data.dataRowData_lng.values,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=10,\n",
    "        color='red',\n",
    "    ),\n",
    "    ))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def obtener_fecha_inicio_fin(semana):\n",
    "    \"\"\"\n",
    "    Función que recibe una semana en formato de fecha y devuelve la fecha de inicio y finalización de esa semana.\n",
    "    \n",
    "    Args:\n",
    "    semana (str o datetime): Semana en formato de fecha. Debe estar en formato 'YYYY-MM-DD'.\n",
    "    \n",
    "    Returns:\n",
    "    fecha_inicio (str): Fecha de inicio de la semana en formato 'YYYY-MM-DD'.\n",
    "    fecha_fin (str): Fecha de finalización de la semana en formato 'YYYY-MM-DD'.\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(semana, str):\n",
    "        semana = datetime.datetime.strptime(semana, '%Y-%m-%d')\n",
    "        \n",
    "    dia_semana = semana.weekday()\n",
    "    \n",
    "    fecha_inicio = semana - datetime.timedelta(days=dia_semana)\n",
    "    fecha_fin = fecha_inicio + datetime.timedelta(days=6)\n",
    "    \n",
    "    fecha_inicio = fecha_inicio.strftime('%Y-%m-%d')\n",
    "    fecha_fin = fecha_fin.strftime('%Y-%m-%d')\n",
    "    return fecha_inicio, fecha_fin\n",
    "\n",
    "\n",
    "def filter_time_day(data,momento):\n",
    "    \n",
    "    switch_dict={\n",
    "        'noche': data[((data.updatedAt.dt.hour > 20) & (data.updatedAt.dt.hour < 24))| ((data.updatedAt.dt.hour > 0) & (data.updatedAt.dt.hour < 7))],\n",
    "        'madrugada':  data[(data.updatedAt.dt.hour > 0) & (data.updatedAt.dt.hour < 7)],\n",
    "        'tarde':data[(data.updatedAt.dt.hour > 13) & (data.updatedAt.dt.hour < 20)],\n",
    "        'mañana':data[(data.updatedAt.dt.hour > 7) & (data.updatedAt.dt.hour < 13)]\n",
    "    }\n",
    "    if momento =='noche':\n",
    "        c= data[(data.updatedAt.dt.hour > 20) & (data.updatedAt.dt.hour < 24)]\n",
    "        v= data[data.updatedAt.dt.hour == 0]\n",
    "        m=switch_dict.get('madrugada','valor')\n",
    "        result=pd.concat([c,v,m])\n",
    "        return result\n",
    "    return switch_dict.get(momento,'valor')\n",
    "\n",
    "\n",
    "def filter_week_data(data,fecha):\n",
    "    if isinstance(fecha,int):\n",
    "        data = data[data.createdAt.dt.week == fecha]\n",
    "    else:\n",
    "        week = obtener_fecha_inicio_fin(fecha)\n",
    "        data = data[(data.createdAt >= week[0]) & (data.createdAt <= week[1])]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_min_max_data(data):\n",
    "    \"\"\"Funcion que devuelve los valores de fecha maxima que aparece en los dataframe\n",
    "\n",
    "    Args:\n",
    "        data (dataframe): recibe el dataframe saca fecha maxima y fecha minima\n",
    "\n",
    "    Returns:\n",
    "        tuple:(datatime,datatime) \n",
    "    \"\"\"\n",
    "    fecha_max=data.createdAt.dt.date.max().strftime('%Y-%m-%d')\n",
    "    fecha_min=data.createdAt.dt.date.min().strftime('%Y-%m-%d')\n",
    "    return fecha_min ,fecha_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe_by_specific_day(df: pd.DataFrame, specific_day: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filtra un DataFrame por un día específico en la columna 'createdAt'.\n",
    "\n",
    "    Parameters:\n",
    "        - df: DataFrame original con datos GPS.\n",
    "        - specific_day: Día específico para filtrar, en formato 'YYYY-MM-DD'.\n",
    "\n",
    "    Returns:\n",
    "        - filtered_df: DataFrame filtrado por el día específico.\n",
    "    \"\"\"\n",
    "    # Convertir la columna 'createdAt' a un tipo datetime\n",
    "    df['createdAt']: pd.Series[pd.Timestamp] = pd.to_datetime(df['createdAt'])\n",
    "\n",
    "    # Filtrar por el día específico\n",
    "    specific_day_datetime: pd.Timestamp = pd.to_datetime(specific_day)\n",
    "    filtered_df: pd.DataFrame = df[df['createdAt'].dt.date == specific_day_datetime.date()]\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas para la vaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dataframe_interview_vaca(data): # tratar de filtrar por perimetro porque si hay valores (que los hay)fuera de rango de los -90 90 da error\n",
    "#     data_dis=[]\n",
    "#     data_vel=[]\n",
    "#     data_time=[]\n",
    "#     data_inter= []\n",
    "#     data_in=[]\n",
    "#     data_fin=[]\n",
    "#     data_lat=[x for x in data['dataRowData_lat']]\n",
    "#     data_lng=[x for x in data['dataRowData_lng']]\n",
    "#     for i in range(0,data.shape[0]+1):\n",
    "#         try:\n",
    "#             dista_km= great_circle(tuple(data.iloc[i][['dataRowData_lat','dataRowData_lng']].values),tuple(data.iloc[i+1][['dataRowData_lat','dataRowData_lng']].values)).kilometers\n",
    "#             data_in.append(data.iloc[i][['createdAt']].values[0])\n",
    "#             data_fin.append(data.iloc[i+1][['createdAt']].values[0])\n",
    "#             interval= int(data.iloc[i+1][['createdAt']].values[0].strftime('%H')) - int(data.iloc[i][['createdAt']].values[0].strftime('%H'))\n",
    "#             data_inter.append(interval)\n",
    "#             if dista_km <= 8.:\n",
    "#                 data_dis.append(round(dista_km,3))\n",
    "#             if data.iloc[i].dataRowData_gpsVel:\n",
    "#                 data_vel.append(round(data.iloc[i].dataRowData_gpsVel,3))\n",
    "#                 data_time.append(round(dista_km/data.iloc[i].dataRowData_gpsVel,3))\n",
    "#             else:\n",
    "#                 data_time.append(round(dista_km/pd.Series(data_vel).mean().round(3),3))# les puede dar error si el array de velocidad esta vacio... toma el valor promedio de las velocidades que hay hasta el momento\n",
    "#         except IndexError:\n",
    "#             pass\n",
    "#     df = list(zip(data_in,data_fin,data_lat,data_lng,data_inter,data_dis,data_vel,data_time))\n",
    "#     df = pd.DataFrame(df,columns=['point_ini','point_next' ,'latitud','longitud','interval_time','distancia','velocidad','tiempo']) \n",
    "#     df['aceleracion']= df['velocidad'].diff()/df['tiempo'].diff()\n",
    "#     df['p_distancia']= df['velocidad'] * df['tiempo'] \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conteos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_register_week(data):\n",
    "    week_x= data.groupby(['UUID',data.createdAt.dt.week]).agg({'createdAt':'count'}).rename(columns={'createdAt':'count_register'})\n",
    "    week_x=week_x.reset_index()\n",
    "    return week_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_time_UUID(data,id,fecha_ini,fecha_fin):\n",
    "    df= data[data.UUID==id]\n",
    "    df= df[(df.point_ini.dt.date > pd.to_datetime(fecha_ini)) & (df.point_ini.dt.date < pd.to_datetime(fecha_fin))]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m KMeans\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m cross_val_predict\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "def fit_model(data):\n",
    "    dat= data.fillna(0.0)\n",
    "    X=dat[['p_distancia','velocidad','aceleracion']]\n",
    "    kmeans= KMeans(n_clusters=2,random_state=0).fit(X)\n",
    "    return kmeans\n",
    "\n",
    "def grafico_cluster(data):\n",
    "    counts = data['cluster'].value_counts()\n",
    "    plt.bar(counts.index, counts.values)\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.title('Frecuencia de clusters')\n",
    "\n",
    "    # mostrar el gráfico\n",
    "    return plt.show()\n",
    "\n",
    "def predict_model(model,data):\n",
    "    df = data\n",
    "    df= df.fillna(0.0)\n",
    "    df.loc[(df.aceleracion == np.inf) | (df.aceleracion == -np.inf),'aceleracion']=0.0\n",
    "    x_test = df[[ 'velocidad','aceleracion']].values#\n",
    "    perro = model.predict(x_test)\n",
    "    data['cluster'] = perro\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deteccion proximidad a las aguadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data_by_dates(df: pd.DataFrame, fecha_init: str, fecha_fin : str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Selecciona las filas de un DataFrame correspondientes a una fecha específica.\n",
    "    \n",
    "    Parametros:\n",
    "    - df: DataFrame de pandas que contiene la columna \"createdAt\".\n",
    "    - fecha: Fecha en formato de cadena, en el formato 'YYYY-MM-DD'.\n",
    "    \n",
    "    Returno:\n",
    "    - DataFrame de pandas que contiene solo las filas correspondientes a la fecha especificada.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convertir la columna \"createdAt\" en un objeto datetime\n",
    "    df['createdAt'] = pd.to_datetime(df['createdAt'])\n",
    "\n",
    "    # Seleccionar solo las filas correspondientes a la fecha especificada\n",
    "    fecha_deseada1 = pd.to_datetime(fecha_init).date()\n",
    "    fecha_deseada2 = pd.to_datetime(fecha_fin).date()\n",
    "\n",
    "    nuevo_df = df[(df['createdAt'].dt.date >= fecha_deseada1) & (df['createdAt'].dt.date <= fecha_deseada2)]\n",
    "\n",
    "    return nuevo_df\n",
    "\n",
    "#las funciones update aguada aestan mas arriba\n",
    "\n",
    "def filter_area_peri(data,latitud,longitud,metro):\n",
    "    gdf= gpd.GeoDataFrame(data,crs='EPSG:4326',geometry=gpd.points_from_xy(data.dataRowData_lng,data.dataRowData_lat))\n",
    "    setle_lat=latitud\n",
    "    setle_lng=longitud\n",
    "    punto_referencia= Point(setle_lng,setle_lat)\t\n",
    "    per_kilo= math.sqrt(metro)*0.01\n",
    "    circulo= punto_referencia.buffer(per_kilo/111.32) # valor 1 grado aprox en kilometro en el ecuador \n",
    "    on_perimetro= gdf[gdf.geometry.within(circulo)]\n",
    "    agua = update_aguada(on_perimetro)\n",
    "    on_perimetro = on_perimetro.drop(on_perimetro[on_perimetro['UUID'].isin(agua.deviceMACAddress.unique())].index)\n",
    "    return on_perimetro\n",
    "\n",
    "\n",
    "def gps_aguada(aguadas,df):\n",
    "    movi_agu= df[df.UUID.isin(aguadas.deviceMACAddress)]\n",
    "    data={}\n",
    "    for i in aguadas.deviceMACAddress:\n",
    "        data_de = data_devices(movi_agu,i)\n",
    "        #print(data_de.shape)\n",
    "        data[i]=data_de.iloc[-1][['dataRowData_lat','dataRowData_lng']]\n",
    "    dtf= pd.DataFrame(data).transpose()\n",
    "    return dtf\n",
    "\n",
    "def agua_click(data,vaca,fecha,setle):\n",
    "    aguadas=update_aguada(setle)\n",
    "    dtf= gps_aguada(aguadas,data)\n",
    "    prueba= {}\n",
    "    for i,d in dtf.iterrows():\n",
    "        prueba[i]=filter_area_peri(data,d['dataRowData_lat'] , d['dataRowData_lng'],4.6)\n",
    "    prueb=pd.concat(prueba.values())\n",
    "    day_p=filter_dataframe_by_specific_day(prueb,fecha)# prueba saco obtencion por id\n",
    "    p=data_devices(day_p,vaca)\n",
    "    return p\n",
    "\n",
    "def agua_clicks(data,vaca,fecha,fecha2,setle):\n",
    "    aguadas=update_aguada(setle)\n",
    "    dtf= gps_aguada(aguadas,data)\n",
    "    prueba= {}\n",
    "    for i,d in dtf.iterrows():\n",
    "        prueba[i]=filter_area_peri(data,d['dataRowData_lat'] , d['dataRowData_lng'],4.0)\n",
    "    prueb=pd.concat(prueba.values())\n",
    "    day_p=select_data_by_dates(prueb,fecha,fecha2) \n",
    "    p=data_devices(day_p,vaca)\n",
    "    return p\n",
    "    \n",
    "def result_select(data_values,data):\n",
    "    select=data_values.point_ini.dt.strftime('%H:%M').isin(data.createdAt.dt.strftime('%H:%M').values)\n",
    "    data_values.loc[select,'agua']=1\n",
    "    data_values.agua= data_values.agua.fillna(0)\n",
    "    return data_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dormida_column(df, cluster_val, start_time, end_time):\n",
    "    df['dormida'] = 'NO'\n",
    "    for i, row in df.iterrows():\n",
    "        if row['cluster'] == cluster_val:\n",
    "            hora = pd.to_datetime(row['point_ini']) - pd.Timedelta(hours=3)\n",
    "            if hora.hour >= start_time or hora.hour < end_time:\n",
    "                df.loc[i, 'dormida'] = 'SI'\n",
    "    return df\n",
    "\n",
    "def cosa(numero_horas):\n",
    "    horas = int(numero_horas)\n",
    "    minutos = int((numero_horas - horas) * 60)\n",
    "    segundos = int(((numero_horas - horas) * 60 - minutos) * 60)\n",
    "    return f'{horas}h {minutos}\"{segundos}s'\n",
    "\n",
    "def acumular_diferencia_tiempo(df, cluster_rum, cluster_rum_2):\n",
    "    # Convertir las columnas \"point_ini\" y \"point_next\" en valores de tipo datetime\n",
    "    df[\"point_ini\"] = pd.to_datetime(df[\"point_ini\"])\n",
    "    df[\"point_next\"] = pd.to_datetime(df[\"point_next\"])\n",
    "\n",
    "    # Crear las columnas \"rumeando\", \"pastando\" y \"durmiendo\" y establecer el valor inicial a 0\n",
    "    df[\"rumeando\"] = 0\n",
    "    df[\"pastando\"] = 0\n",
    "    df[\"durmiendo\"] = 0\n",
    "    df[\"bebiendo\"] = 0\n",
    "    \n",
    "    cantidadregistro=0\n",
    "\n",
    "    # Recorrer el DataFrame y sumar los valores de la diferencia entre \"point_ini\" y \"point_next\" según las condiciones dadas\n",
    "    for i, row in df.iterrows():\n",
    "        if row[\"dormida\"] == \"SI\" and row['agua'] == 0:\n",
    "            df.at[i, \"durmiendo\"] += ((row[\"point_next\"] - row[\"point_ini\"]).total_seconds())/3600\n",
    "        elif row[\"cluster\"] == 1 and row[\"dormida\"] == \"NO\" and row['agua'] == 0:\n",
    "            df.at[i, \"rumeando\"] += ((row[\"point_next\"] - row[\"point_ini\"]).total_seconds())/3600\n",
    "        elif row[\"cluster\"] == 0 and row['agua'] == 0:\n",
    "            df.at[i, \"pastando\"] += ((row[\"point_next\"] - row[\"point_ini\"]).total_seconds())/3600\n",
    "        elif row['agua'] == 1 :\n",
    "            df.at[i, \"bebiendo\"] += ((row[\"point_next\"] - row[\"point_ini\"]).total_seconds())/3600\n",
    "        cantidadregistro +=1\n",
    "    # Crear un nuevo DataFrame con los valores totales de cada actividad\n",
    "    total_df = pd.DataFrame({\n",
    "        \"rumiando\": [cosa(df[\"rumeando\"].sum())],\n",
    "        \"pastando\": [cosa(df[\"pastando\"].sum())],\n",
    "        \"durmiendo\": [cosa(df[\"durmiendo\"].sum())],\n",
    "        \"bebiendo\": [cosa(df[\"bebiendo\"].sum())],\n",
    "        \"promedio_ith\":df['ITH'].mean(),\n",
    "        \"cant_registro\": cantidadregistro\n",
    "    })\n",
    "    \n",
    "    return total_df\n",
    "#pastoreo =0, rumia= 1\n",
    "\n",
    "def separador_por_dia(df):\n",
    "    df['fecha']= pd.to_datetime(df.point_ini).dt.date\n",
    "    \n",
    "    diarios= {}\n",
    "    for fecha,grupo in df.groupby(df['point_ini'].dt.date):\n",
    "        diarios[fecha]=acumular_diferencia_tiempo(grupo,1,0)\n",
    "    diarios=pd.concat(diarios.values(),keys=diarios.keys(),axis=0)\n",
    "    diarios=diarios.reset_index(level=1).drop(columns=['level_1'])\n",
    "    return diarios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_interview_vaca(data): # tratar de filtrar por perimetro porque si hay valores (que los hay)fuera de rango de los -90 90 da error\n",
    "    data_dis=[]\n",
    "    data_vel=[]\n",
    "    data_time=[]\n",
    "    data_inter= []\n",
    "    data_in=[]\n",
    "    data_fin=[]\n",
    "    data_lat=[x for x in data['dataRowData_lat']]\n",
    "    data_lng=[x for x in data['dataRowData_lng']]\n",
    "    for i in range(0,data.shape[0]+1):\n",
    "        try:\n",
    "            dista_km= great_circle(tuple(data.iloc[i][['dataRowData_lat','dataRowData_lng']].values),tuple(data.iloc[i+1][['dataRowData_lat','dataRowData_lng']].values)).kilometers\n",
    "            data_in.append(data.iloc[i][['createdAt']].values[0])\n",
    "            data_fin.append(data.iloc[i+1][['createdAt']].values[0])\n",
    "            interval= int(data.iloc[i+1][['createdAt']].values[0].strftime('%H')) - int(data.iloc[i][['createdAt']].values[0].strftime('%H'))\n",
    "            data_inter.append(interval)\n",
    "            if dista_km <= 8.:\n",
    "                data_dis.append(round(dista_km,3))\n",
    "            if data.iloc[i].dataRowData_gpsVel:\n",
    "                data_vel.append(round(data.iloc[i].dataRowData_gpsVel,3))\n",
    "                data_time.append(round(dista_km/data.iloc[i].dataRowData_gpsVel,3))\n",
    "            else:\n",
    "                data_time.append(round(dista_km/pd.Series(data_vel).mean().round(3),3))# les puede dar error si el array de velocidad esta vacio... toma el valor promedio de las velocidades que hay hasta el momento\n",
    "        except IndexError:\n",
    "            pass\n",
    "    df = list(zip(data_in,data_fin,data_lat,data_lng,data_inter,data_dis,data_vel,data_time))\n",
    "    df = pd.DataFrame(df,columns=['point_ini','point_next' ,'latitud','longitud','interval_time','distancia','velocidad','tiempo']) \n",
    "    df['aceleracion']= df['velocidad'].diff()/df['tiempo'].diff()\n",
    "    df['p_distancia']= df['velocidad'] * df['tiempo'] \n",
    "    \n",
    "    return df\n",
    "\n",
    "def data_interview(data):\n",
    "    vacas= data.UUID.unique()\n",
    "    data_nuevo={}\n",
    "    for i in vacas:\n",
    "        dat=data_devices(data,i)\n",
    "        data_nuevo[i]=dataframe_interview_vaca(dat)\n",
    "    merge_data= pd.concat(data_nuevo.values(),keys=data_nuevo.keys(),axis=0)\n",
    "    merge_data.reset_index(level=0,inplace=True)\n",
    "    merge_data.rename(columns={'level_0':'UUID'},inplace=True)\n",
    "    merge_data.reset_index(inplace=True)\n",
    "    merge_data.set_index(\"UUID\")\n",
    "    merge_data.drop(columns=\"index\",inplace=True)\n",
    "    return merge_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corte' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m corte\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corte' is not defined"
     ]
    }
   ],
   "source": [
    "corte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creacion de datos de prueba\n",
    "* se tomas aquellos registros con mayor frecuencia y de registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('data_clean_gps.csv',index_col='Unnamed: 0')\n",
    "df.createdAt=pd.to_datetime(df.createdAt) \n",
    "df.updatedAt=pd.to_datetime(df.updatedAt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shapely\\predicates.py:946: RuntimeWarning: invalid value encountered in within\n",
      "  return lib.within(a, b, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "prueba= filter_area_perimetro(df,'MACSA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pru= data_interview(prueba) #se transforma todos los registros a datos con los que vamos a trabajar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counUID = prueba.groupby(prueba.createdAt.dt.month).agg({'UUID':'count'}).rename(columns={'UUID':'count_uid'})\n",
    "counUID.sort_values('count_uid',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " dt_vaca=  data_devices(on_perimetro,select)\n",
    "    dt_vaca.createdAt= pd.to_datetime(dt_vaca.createdAt)\n",
    "    st.write(f'{dt_vaca.createdAt.dt.year.unique()}')\n",
    "    data_week= dt_vaca['createdAt'].groupby(dt_vaca.createdAt.dt.strftime('%U')).aggregate(['count']).rename(columns={'count':'count_register'})\n",
    "    data_week=data_week.reset_index()\n",
    "    data_week.createdAt = data_week.createdAt.apply(lambda x : int(x)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shapely\\predicates.py:946: RuntimeWarning: invalid value encountered in within\n",
      "  return lib.within(a, b, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prueba2= filter_area_perimetro(df,'La Florida')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaca_florida= data_devices(prueba2,'0004A30B00F82747')\n",
    "filter_day=select_data_by_dates(vaca_florida,'2022-05-30','2022-08-26')\n",
    "process_devi= data_interview(filter_day)\n",
    "process_devi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=agua_click(prueba2,'0004A30B00F82747','2022-08-26','620e6e5e60543d0026a01f0e')\n",
    "# vaca_f= result_select(process_devi,a)\n",
    "# vaca_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_month= prueba[prueba.createdAt.dt.month==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=clust_month.groupby('UUID').agg({'UUID':'count'}).rename(columns={'UUID':'count_uid'}).sort_values('count_uid',ascending=False)\n",
    "# x=x.sort_values('count_uid',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_entre=clust_month[clust_month.UUID.isin(x.index[:4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacas_tarde=filter_time_day(data_entre,'noche')\n",
    "vacas_modelo=data_interview(vacas_tarde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaca_mu= data_devices(prueba,'0004A30B00F89C52') # datos crudos de una vaca especifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaca= filter_dataframe_by_specific_day(vaca_mu,'2023-03-30') # filtrado por dia en especifico de esta vaca DATOS CRUDOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaca_t=data_interview(vaca) # SE TRANSFORMA LOS DATOS A DATOS CON LOS QUE SE TRABAJA\n",
    "vaca_t= vaca_t.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaca_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "vacas_modelo=vacas_modelo.fillna(0.0)\n",
    "\n",
    "vacas_modelo.loc[(vacas_modelo.aceleracion == np.inf) | (vacas_modelo.aceleracion == -np.inf),'aceleracion']=0.0\n",
    "vacas_modelo.loc[(vacas_modelo.aceleracion == np.inf) | (vacas_modelo.aceleracion == -np.inf)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creacion de datos optios para mejor identificacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Generar dataframe para pastoreo\n",
    "pastoreo_df = pd.DataFrame({\n",
    "    'distancia': np.random.normal(loc=0.025, scale=0.01, size=7000),\n",
    "    'velocidad': np.random.normal(loc=0.2, scale=0.05, size=7000),\n",
    "    'tiempo': np.random.normal(loc=0.15, scale=0.05, size=7000),\n",
    "    'aceleracion': np.random.normal(loc=-0.2, scale=0.1, size=7000),\n",
    "    'actividad': 'pastoreo'\n",
    "})\n",
    "\n",
    "# Generar dataframe para rumia\n",
    "rumia_df = pd.DataFrame({\n",
    "    'distancia': np.random.normal(loc=0.005, scale=0.002, size=7000),\n",
    "    'velocidad': np.random.normal(loc=0.01, scale=0.002, size=7000),\n",
    "    'tiempo': np.random.normal(loc=0.5, scale=0.05, size=7000),\n",
    "    'aceleracion': np.random.normal(loc=-0.05, scale=0.02, size=7000),\n",
    "    'actividad': 'rumia'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEZCLADO Y CONCATENADO DE EL DATAFRAME PARA ENTRENAR EL MODELO\n",
    "concatenado = pd.concat([pastoreo_df, rumia_df], axis=0, ignore_index=True)\n",
    "concatenado= concatenado.sample(frac=1,random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASIGNACION DE NUMEROS IDENTIFICATORIOS\n",
    "cambio={'pastoreo':0,'rumia':1}\n",
    "concatenado.actividad= concatenado.actividad.map(cambio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenado.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion y entrenamiento del modelo de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## probando svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(concatenado)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "clusters = dbscan.fit_predict(data_scaled)\n",
    "\n",
    "plt.scatter(data_scaled[:,0], data_scaled[:,1], c=clusters, cmap='viridis')\n",
    "plt.xlabel('Aceleración')\n",
    "plt.ylabel('Velocidad')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= concatenado[['velocidad', 'aceleracion', 'distancia']]\n",
    "y= concatenado['actividad']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Precisión:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando logisticREgression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "# X_train, X_test, y_train, y_test = train_test_split(concatenado[['velocidad', 'aceleracion', 'distancia']], \n",
    "#                                                     concatenado['actividad'], \n",
    "#                                                     test_size=0.2, \n",
    "#                                                     random_state=42)\n",
    "\n",
    "X= concatenado[['velocidad', 'aceleracion', 'distancia']]\n",
    "y= concatenado['actividad']\n",
    "# Crear un modelo de regresión logística\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# Predecir la actividad en los datos de prueba\n",
    "y_pred = logreg.predict(X)\n",
    "concatenado['cluster'] = y_pred\n",
    "# Evaluar el desempeño del modelo\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Exactitud del modelo: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## usando Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "X = concatenado[['velocidad','aceleracion']]\n",
    "y= concatenado['actividad']\n",
    "\n",
    "# crear el modelo de K-means con 5 clusters\n",
    "kmeans = KMeans(n_clusters=2,random_state=0).fit(X,y)\n",
    "\n",
    "# ajustar el modelo a los datos\n",
    "\n",
    "\n",
    "labels = kmeans.labels_\n",
    "\n",
    "concatenado['cluster'] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= StandardScaler()\n",
    "data_sca= scaler.fit_transform(concatenado[['velocidad',  'aceleracion']])\n",
    "y=concatenado['actividad']\n",
    "kmeans= KMeans(n_clusters=2 , random_state=42)\n",
    "kmeans.fit(data_sca,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenado=predict_model(kmeans,concatenado[[ 'velocidad',  'aceleracion']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico_cluster(concatenado)#6500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model(kmeans,vaca_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico_cluster(vaca_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cambio_ac={0:'pastoreo',1:'quieta'}\n",
    "vaca_t.cluster= vaca_t.cluster.map(cambio_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=agua_click(prueba,'0004A30B00F89C52','2023-03-30','63ecf27ba9f1a40025792acf')\n",
    "d=result_select(vaca_t,s)\n",
    "vaca_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= add_dormida_column(vaca_t,1,20,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separador_por_dia(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=predict_model(kmeans,x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= add_dormida_column(x,1,20,6)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= agua_clicks(prueba,'0004A30B00F89C52','2023-03-17','2023-04-10','63ecf27ba9f1a40025792acf')\n",
    "x=result_select(x,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respuesta_diagnostico(valor,min,max):\n",
    "\n",
    "    if valor > min and valor < (max+(max*0.05)):\n",
    "        result='normal'\n",
    "    elif valor > (min-(min*0.25)) and valor < (max+(max*0.25)):\n",
    "        result= 'atencion!' \n",
    "    else:\n",
    "        result= 'mal'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnostico_devices(df):\n",
    "    rumia=[float(x.split('h')[0]) for x in df['rumiando']]\n",
    "    pastoreo=[float(x.split('h')[0]) for x in df['pastando']]\n",
    "    durmiendo=[float(x.split('h')[0]) for x in df['durmiendo']]\n",
    "    agua=[float(x.split('h')[0]) for x in df['bebiendo']]\n",
    "    can_r=['optimo' if x >= 72 else 'poco' if x < 68 else 'no optimo' for x in df['cant_registro'] ]\n",
    "    \n",
    "    diag= pd.DataFrame({\n",
    "        'fecha':[x for x in df.index],\n",
    "        'rumiando':[respuesta_diagnostico(x,6,8) for x in rumia] ,\n",
    "        'pastando':[respuesta_diagnostico(x,8,12) for x in pastoreo],\n",
    "        'durmiendo':[respuesta_diagnostico(x,5,8) for x in durmiendo],\n",
    "        'agua':[respuesta_diagnostico(x,1,4) for x in agua] ,\n",
    "        'cant_registro':can_r,\n",
    "    })\n",
    "    return diag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prueba de api funcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papas= requests.get('http://localhost:8000/conducta_vaca_periodo/MACSA/0004A30B00F89C52/2023-03-17/2023-04-10')\n",
    "\n",
    "data= json.loads(papas.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papa_url= requests.get('http://localhost:8000//informacion_por_finca/MACSA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papa_url= requests.get('http://localhost:8000/filtro_por_una_vaca_establecimiento/MACSA/0004A30B00F89C52')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= json.loads(papa_url.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result=pd.DataFrame(data['datos'])\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resul8=pd.DataFrame(data['resumen_datos'])\n",
    "df_resul8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    horas =int(x.replace(',','').split('h')[0])\n",
    "    minutos=int(x.replace(',','').strip().split('h')[1].split('min')[0])\n",
    "    if minutos > 50:\n",
    "        horas +=1\n",
    "    return horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resul8[['rumiando','pastando','durmiendo','bebiendo']]= df_resul8[['rumiando','pastando','durmiendo','bebiendo']].applymap(lambda x: transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(df_resul8['rumiando'])\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Frecuencia de clusters')\n",
    "\n",
    "# mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_resul1=pd.DataFrame(data['diagnostico'])\n",
    "df_resul1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papa2= requests.get('http://localhost:8000/conducta_vaca/MACSA/0004A30B00F89C52/2023-03-30')\n",
    "\n",
    "data2= json.loads(papa2.text)\n",
    "\n",
    "df_result2=pd.DataFrame(data2['datos'])\n",
    "df_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result3=pd.DataFrame(data2['resumen_datos'])\n",
    "df_result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result4=pd.DataFrame(data2['diagnostico'])\n",
    "df_result4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_setith= mongo_data('settlementithcounts')\n",
    "df_setith.settlementId =df_setith.settlementId.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pru= df_setith[df_setith.settlementId =='63ecf27ba9f1a40025792acf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba=pru[pru.createdAt.dt.date ==pd.to_datetime('2023-03-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preuva_ith= pd.merge(vaca_t,prueba[['createdAt', 'ITH']],left_on=vaca_t.point_ini.dt.hour, right_on=prueba['createdAt'].dt.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_ith(data, fecha,asentamiento_id):\n",
    "    df_setith= mongo_data('settlementithcounts')\n",
    "    df_setith.settlementId =df_setith.settlementId.astype(str)\n",
    "    pru= df_setith[df_setith.settlementId ==asentamiento_id]\n",
    "    prueba=pru[pru.createdAt.dt.date ==pd.to_datetime(fecha)]\n",
    "    if prueba.shape[0]!=0:\n",
    "        prueba_ith= pd.merge(data,prueba[['createdAt', 'ITH']],left_on=data.point_ini.dt.hour, right_on=prueba['createdAt'].dt.hour)\n",
    "        prueba_ith= prueba_ith.drop(columns=['key_0','createdAt'])\n",
    "        return prueba_ith\n",
    "    else:\n",
    "        return f'fecha vacia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_iths(data,asentamiento_id):\n",
    "    df_setith= mongo_data('settlementithcounts')\n",
    "    df_setith.settlementId =df_setith.settlementId.astype(str)\n",
    "    pru= df_setith[df_setith.settlementId ==asentamiento_id]\n",
    "    aux= {}\n",
    "    for fecha in data.point_ini.dt.date.unique():\n",
    "        prueba=pru[pru.createdAt.dt.date== fecha]\n",
    "        dataq=data[data.point_ini.dt.date  == fecha]\n",
    "        aux[fecha]= pd.merge(dataq,prueba[['createdAt', 'ITH']],left_on=dataq.point_ini.dt.hour, right_on=prueba['createdAt'].dt.hour)\n",
    "    prueb= pd.concat(aux.values())  \n",
    "    prueb= prueb.drop(columns=['key_0','createdAt'])  \n",
    "    return prueb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= filter_time_UUID(pru,'0004A30B00F89C52','2023-03-17','2023-04-17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = agregar_iths(x,'63ecf27ba9f1a40025792acf') #,'2023-03-30'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean([4,5,3,2,7,9,8,0,5,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agua= agua_clicks(prueba,'0004A30B00F89C52','2023-03-29','2023-03-30', '63ecf27ba9f1a40025792acf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UUID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>createdAt</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           UUID\n",
       "createdAt      \n",
       "11            2\n",
       "15            1\n",
       "19            3\n",
       "21            1\n",
       "22            1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruebGroup= agua.groupby([agua.createdAt.dt.hour]).agg({'UUID':'count'})\n",
    "pruebGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupAguada= agua.groupby([agua.createdAt.dt.hour]).agg({'UUID':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UUID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>createdAt</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           UUID\n",
       "createdAt      \n",
       "0             9\n",
       "1            12\n",
       "2             9\n",
       "3             9\n",
       "4            10\n",
       "5            10\n",
       "6            12\n",
       "7            13\n",
       "8            13\n",
       "9             9\n",
       "10            6\n",
       "11           15\n",
       "12           12\n",
       "13            6\n",
       "14            3\n",
       "15            6\n",
       "16            9\n",
       "17            4\n",
       "18            5\n",
       "19           12\n",
       "20            8\n",
       "21            6\n",
       "22           15\n",
       "23           15"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupAguada"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c63d8c7d738c2960218a10995aedf0a7f67a49a231e71037adf0440953cdb45b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
